{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Visualization Notebook\n",
    "\n",
    "This notebook helps visualize the transformer's attention mechanism for two stories. The data includes StoryID, Premise, Initial, Counterfactual, Original Ending, Edited Ending, and Generated Text.\n",
    "\n",
    "## Instructions\n",
    "1. Select a model from the dropdown menu.\n",
    "2. Select a story ID from the dropdown menu.\n",
    "3. The visualizations will update automatically based on your selections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from bertviz.bertviz import head_view, model_view\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Attention Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /data/agirard/Projects/StoryRewriterAttention/data/test_data_sample-attention.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StoryID</th>\n",
       "      <th>Premise</th>\n",
       "      <th>Initial</th>\n",
       "      <th>Counterfactual</th>\n",
       "      <th>Original Ending</th>\n",
       "      <th>Edited Ending</th>\n",
       "      <th>Generated Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca8a7f8d-7f63-422f-8007-c4a26bb8e889</td>\n",
       "      <td>Ela was babysitting.</td>\n",
       "      <td>Her young charge wanted chicken nuggets.</td>\n",
       "      <td>Her young charge wanted some hot cocoa.</td>\n",
       "      <td>Ela checked, but there were none in the freeze...</td>\n",
       "      <td>Ela checked, but there were none in the pantry...</td>\n",
       "      <td>Ela checked, but there were none in the freeze...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9387e571-2819-4e29-bedb-a35f0410da51</td>\n",
       "      <td>I wanted to make hot chocolate.</td>\n",
       "      <td>I took milk and warmed it up.</td>\n",
       "      <td>I didn't have the ingredients to make it though.</td>\n",
       "      <td>Then, I added cocoa powder and stirred it all ...</td>\n",
       "      <td>I needed cocoa powder. I tasted it, but it was...</td>\n",
       "      <td>I took milk and warmed it up. Then, I added co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                StoryID                          Premise  \\\n",
       "0  ca8a7f8d-7f63-422f-8007-c4a26bb8e889             Ela was babysitting.   \n",
       "1  9387e571-2819-4e29-bedb-a35f0410da51  I wanted to make hot chocolate.   \n",
       "\n",
       "                                    Initial  \\\n",
       "0  Her young charge wanted chicken nuggets.   \n",
       "1             I took milk and warmed it up.   \n",
       "\n",
       "                                     Counterfactual  \\\n",
       "0           Her young charge wanted some hot cocoa.   \n",
       "1  I didn't have the ingredients to make it though.   \n",
       "\n",
       "                                     Original Ending  \\\n",
       "0  Ela checked, but there were none in the freeze...   \n",
       "1  Then, I added cocoa powder and stirred it all ...   \n",
       "\n",
       "                                       Edited Ending  \\\n",
       "0  Ela checked, but there were none in the pantry...   \n",
       "1  I needed cocoa powder. I tasted it, but it was...   \n",
       "\n",
       "                                      Generated Text  \n",
       "0  Ela checked, but there were none in the freeze...  \n",
       "1  I took milk and warmed it up. Then, I added co...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to load data from a CSV file\n",
    "def load_data(file_path):\n",
    "    if not file_path.exists():\n",
    "        print(f\"Data path {file_path} does not exist.\")\n",
    "        return None\n",
    "    print(f\"Loading data from {file_path}\")\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Load data and display\n",
    "data_path = Path('/data/agirard/Projects/StoryRewriterAttention/data/test_data_sample-attention.csv')\n",
    "data = load_data(data_path)\n",
    "\n",
    "if data is not None:\n",
    "    display(data.head())  # Display the first few rows of the data\n",
    "\n",
    "\n",
    "# Function to get attention data from a given directory and story ID\n",
    "def get_attention_data(attention_path, story_id):\n",
    "    attention_dir = attention_path / str(story_id)\n",
    "    logger.info(f\"Loading attention data from {attention_dir}\")\n",
    "\n",
    "    if not attention_dir.exists():\n",
    "        logger.error(f\"Attention directory does not exist: {attention_dir}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        encoder_attentions = [np.load(attention_dir / f'encoder_attentions_layer_{i}.npy') for i in range(12)]\n",
    "        logger.info(f\"Loaded encoder attentions for layers 0-11\")\n",
    "        decoder_attentions = [np.load(attention_dir / f'decoder_attentions_layer_{i}.npy') for i in range(12)]\n",
    "        logger.info(f\"Loaded decoder attentions for layers 0-11\")\n",
    "        cross_attentions = [np.load(attention_dir / f'cross_attentions_layer_{i}.npy') for i in range(12)]\n",
    "        logger.info(f\"Loaded cross attentions for layers 0-11\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading attention arrays: {e}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        with open(attention_dir / \"tokens.json\") as f:\n",
    "            tokens = json.load(f)\n",
    "            logger.info(\"Loaded tokens.json\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading tokens.json: {e}\")\n",
    "        return None\n",
    "\n",
    "    encoder_text = tokens.get('encoder_text', [])\n",
    "    generated_text = tokens.get('generated_text', \"\")\n",
    "    generated_text_tokens = tokens.get('generated_text_tokens', [])\n",
    "\n",
    "    logger.info(\"Loaded encoder_text: %s\", encoder_text)\n",
    "    logger.info(\"Loaded generated_text: %s\", generated_text)\n",
    "    logger.info(\"Loaded generated_text_tokens: %s\", generated_text_tokens)\n",
    "\n",
    "    return encoder_attentions, decoder_attentions, cross_attentions, encoder_text, generated_text, generated_text_tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Dropdown Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model options for the dropdown\n",
    "model_options = [\n",
    "    \"model_2024-03-22-10\",\n",
    "    \"model_2024-04-09-22\",\n",
    "    \"model_2024-04-08-13\",\n",
    "    \"model_2024-03-22-15\",\n",
    "    \"model_2024-04-10-10\",\n",
    "    \"model_2024-04-08-09\",\n",
    "    \"model_2024-04-10-14\",\n",
    "    \"model_2024-05-13-17\",\n",
    "    \"model_2024-05-14-20\"\n",
    "]\n",
    "\n",
    "# Create a dropdown widget for model selection\n",
    "model_dropdown = widgets.Dropdown(\n",
    "    options=model_options,\n",
    "    description='Model:',\n",
    "    value=model_options[0]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTViz Visualization Function for Story 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeeedaf336304d819745f3b6a524d344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h2>Story 1 Visualization</h2>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d36af0e65c548cfbcf7761d6c2afda8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Model:', options=('model_2024-03-22-10', 'model_2024-04-09-22', 'model_2024-04-08-13', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b1b89ca7d64e1bb2369c22c172a673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading attention data from /data/agirard/Projects/StoryRewriterAttention/data/model_2024-03-22-10/attentions/ca8a7f8d-7f63-422f-8007-c4a26bb8e889\n",
      "INFO:__main__:Loaded encoder attentions for layers 0-11\n",
      "INFO:__main__:Loaded decoder attentions for layers 0-11\n",
      "INFO:__main__:Loaded cross attentions for layers 0-11\n",
      "INFO:__main__:Loaded tokens.json\n",
      "INFO:__main__:Loaded encoder_text: ['▁El', 'a', '▁was', '▁baby', 's', 'i', 'tting', '.', '▁Her', '▁young', '▁charge', '▁wanted', '▁chicken', '▁nu', 'g', 'get', 's', '.', '▁El', 'a', '▁checked', ',', '▁but', '▁there', '▁were', '▁none', '▁in', '▁the', '▁freezer', '.', '▁She', '▁went', '▁to', '▁McDonald', \"'\", 's', '▁and', '▁bought', '▁some', '▁nu', 'g', 'get', 's', '.', '▁The', '▁child', '▁was', '▁happy', '▁with', '▁his', '▁nu', 'g', 'get', 's', '.', '</s>', '▁El', 'a', '▁was', '▁baby', 's', 'i', 'tting', '.', '▁Her', '▁young', '▁charge', '▁wanted', '▁some', '▁hot', '▁coco', 'a', '.', '</s>']\n",
      "INFO:__main__:Loaded generated_text: Ela checked, but there were none in the freezer. She went to McDonald's and bought some hot cocoa. The child was happy with his hot cocoa.\n",
      "INFO:__main__:Loaded generated_text_tokens: ['<pad>', '▁El', 'a', '▁checked', ',', '▁but', '▁there', '▁were', '▁none', '▁in', '▁the', '▁freezer', '.', '▁She', '▁went', '▁to', '▁McDonald', \"'\", 's', '▁and', '▁bought', '▁some', '▁hot', '▁coco', 'a', '.', '▁The', '▁child', '▁was', '▁happy', '▁with', '▁his', '▁hot', '▁coco', 'a', '.', '</s>']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 attention shape before squeeze: (12, 12, 37, 74)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot select an axis to squeeze out which has size not equal to one",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m display(output_bertviz_story1)\n\u001b[1;32m     50\u001b[0m \u001b[39m# Initialize the BERTViz visualization with the default values for the first story\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m update_bertviz_visualization_story1(model_dropdown\u001b[39m.\u001b[39;49mvalue)\n",
      "Cell \u001b[0;32mIn[18], line 25\u001b[0m, in \u001b[0;36mupdate_bertviz_visualization_story1\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     18\u001b[0m tokens \u001b[39m=\u001b[39m {\n\u001b[1;32m     19\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mencoder\u001b[39m\u001b[39m'\u001b[39m: encoder_text,\n\u001b[1;32m     20\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdecoder\u001b[39m\u001b[39m'\u001b[39m: generated_text_tokens\n\u001b[1;32m     21\u001b[0m }\n\u001b[1;32m     23\u001b[0m \u001b[39m# BERTViz expects attention in shape [batch_size, num_layers, num_heads, seq_len, seq_len]\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39m# and tokens for the encoder and decoder separately\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m model_view(\n\u001b[1;32m     26\u001b[0m     encoder_attention\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     27\u001b[0m     decoder_attention\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     28\u001b[0m     cross_attention\u001b[39m=\u001b[39;49mcross_attentions,\n\u001b[1;32m     29\u001b[0m     encoder_tokens\u001b[39m=\u001b[39;49mtokens[\u001b[39m'\u001b[39;49m\u001b[39mencoder\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     30\u001b[0m     decoder_tokens\u001b[39m=\u001b[39;49mtokens[\u001b[39m'\u001b[39;49m\u001b[39mdecoder\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m     31\u001b[0m )\n",
      "File \u001b[0;32m/data/agirard/Projects/StoryRewriterAttention/bertviz/bertviz/model_view.py:167\u001b[0m, in \u001b[0;36mmodel_view\u001b[0;34m(attention, tokens, sentence_b_start, prettify_tokens, display_mode, encoder_attention, decoder_attention, cross_attention, encoder_tokens, decoder_tokens, include_layers, include_heads, html_action)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[39mif\u001b[39;00m include_heads \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m             include_heads \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(n_heads))\n\u001b[0;32m--> 167\u001b[0m         cross_attention \u001b[39m=\u001b[39m format_attention(cross_attention, include_layers, include_heads)\n\u001b[1;32m    168\u001b[0m         attn_data\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    169\u001b[0m             {\n\u001b[1;32m    170\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mCross\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m             }\n\u001b[1;32m    175\u001b[0m         )\n\u001b[1;32m    176\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/data/agirard/Projects/StoryRewriterAttention/bertviz/bertviz/util.py:13\u001b[0m, in \u001b[0;36mformat_attention\u001b[0;34m(attention, layers, heads)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(layer_attention\u001b[39m.\u001b[39mshape) \u001b[39m!=\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[1;32m     12\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLayer \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m attention tensor does not have the correct number of dimensions. Expected 4D, got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(layer_attention\u001b[39m.\u001b[39mshape)\u001b[39m}\u001b[39;00m\u001b[39mD\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m layer_attention \u001b[39m=\u001b[39m layer_attention\u001b[39m.\u001b[39;49msqueeze(\u001b[39m0\u001b[39;49m)  \u001b[39m# Remove batch dimension\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLayer \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m attention shape after squeeze: \u001b[39m\u001b[39m{\u001b[39;00mlayer_attention\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[39mif\u001b[39;00m heads:\n",
      "\u001b[0;31mValueError\u001b[0m: cannot select an axis to squeeze out which has size not equal to one"
     ]
    }
   ],
   "source": [
    "# Function to update BERTViz visualization for the first story\n",
    "def update_bertviz_visualization_story1(model):\n",
    "    story_id = 'ca8a7f8d-7f63-422f-8007-c4a26bb8e889'\n",
    "    attention_path = Path(f'/data/agirard/Projects/StoryRewriterAttention/data/{model}/attentions')\n",
    "    attention_data = get_attention_data(attention_path, story_id)\n",
    "\n",
    "    if attention_data:\n",
    "        encoder_attentions, decoder_attentions, cross_attentions, encoder_text, generated_text, generated_text_tokens = attention_data\n",
    "\n",
    "        # Ensure the cross-attention tensors are 5D\n",
    "        cross_attentions = np.stack(cross_attentions)  # (num_layers, batch_size, num_heads, seq_len, seq_len)\n",
    "        if cross_attentions.ndim == 4:  # If there's no batch dimension\n",
    "            cross_attentions = cross_attentions[np.newaxis, ...]  # Add a batch dimension\n",
    "\n",
    "        # Transpose to match the expected shape [batch_size, num_layers, num_heads, seq_len, seq_len]\n",
    "        cross_attentions = np.transpose(cross_attentions, (1, 0, 2, 3, 4))\n",
    "\n",
    "        tokens = {\n",
    "            'encoder': encoder_text,\n",
    "            'decoder': generated_text_tokens\n",
    "        }\n",
    "\n",
    "        # BERTViz expects attention in shape [batch_size, num_layers, num_heads, seq_len, seq_len]\n",
    "        # and tokens for the encoder and decoder separately\n",
    "        model_view(\n",
    "            encoder_attention=None,\n",
    "            decoder_attention=None,\n",
    "            cross_attention=cross_attentions,\n",
    "            encoder_tokens=tokens['encoder'],\n",
    "            decoder_tokens=tokens['decoder']\n",
    "        )\n",
    "\n",
    "# Create an interactive output area for BERTViz for the first story\n",
    "output_bertviz_story1 = widgets.Output()\n",
    "\n",
    "# Function to handle dropdown value changes for BERTViz for the first story\n",
    "def on_bertviz_value_change_story1(change):\n",
    "    with output_bertviz_story1:\n",
    "        output_bertviz_story1.clear_output()\n",
    "        update_bertviz_visualization_story1(model_dropdown.value)\n",
    "\n",
    "# Attach the update function to dropdown changes\n",
    "model_dropdown.observe(on_bertviz_value_change_story1, names='value')\n",
    "\n",
    "# Display the dropdown and output area for BERTViz for the first story\n",
    "display(widgets.HTML(\"<h2>Story 1 Visualization</h2>\"))\n",
    "display(model_dropdown)\n",
    "display(output_bertviz_story1)\n",
    "\n",
    "# Initialize the BERTViz visualization with the default values for the first story\n",
    "update_bertviz_visualization_story1(model_dropdown.value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.9 ('flask-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87b148e98bf01e93bc526dba115038a45ade1bd1071f911590cffb4d3ecbe0f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
